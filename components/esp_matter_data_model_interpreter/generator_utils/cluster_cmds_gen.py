# SPDX-FileCopyrightText: 2025 Espressif Systems (Shanghai) CO LTD
# SPDX-License-Identifier: Apache-2.0
import argparse
import os
import re
import sys
import xml.etree.ElementTree as ET

import yaml

static_text_register_command_cb_fn = """
esp_err_t register_command_cb(esp_matter::cluster_t *cluster, uint32_t cluster_id, uint32_t command_id, uint8_t flag)
{
    if (flag & esp_matter::COMMAND_FLAG_GENERATED) {
      esp_matter::command::create(cluster, command_id, esp_matter::COMMAND_FLAG_GENERATED, NULL);
      return ESP_OK;
    }

    esp_err_t result = ESP_FAIL;

    for (size_t i = 0; i < sizeof(cluster_cb_map) / sizeof(cluster_cb_map[0]); ++i) {
        const auto& cluster_cb = cluster_cb_map[i];
        if (cluster_id == cluster_cb.cluster_id) {
            if (flag & esp_matter::COMMAND_FLAG_ACCEPTED) {
                const CommandCallbackMap_t *cmd_map = *cluster_cb.accepted_cmds;
                if (cmd_map) {
                    for (; cmd_map->cmd_cb != nullptr; ++cmd_map) {
                        if (cmd_map->cmd_id == command_id) {
                            esp_matter::command::create(cluster, command_id, esp_matter::COMMAND_FLAG_ACCEPTED, cmd_map->cmd_cb);
                            result = ESP_OK;
                            break;
                        }
                    }
                }
                // Commands not present in the accepted command list, can be created with NULL callback
                // TODO: Check if any stricter checks are needed before creating commands
                if (result != ESP_OK) {
                    esp_matter::command::create(cluster, command_id, esp_matter::COMMAND_FLAG_ACCEPTED, NULL);
                    result = ESP_OK;
                }
                break;
            }
        }
    }
    return result;
}
"""
static_text_cluster_plugin_init_fn = """
esp_err_t cluster_plugin_init(esp_matter::cluster_t *cluster, uint32_t cluster_id)
{
    esp_err_t ret = ESP_FAIL;
    for (auto& cluster_cb : cluster_cb_map) {
        if (cluster_id == cluster_cb.cluster_id) {
            if (cluster_cb.init_fn) {
                esp_matter::cluster::set_plugin_server_init_callback(cluster, cluster_cb.init_fn);
            }
            esp_matter::cluster::add_function_list(cluster, cluster_cb.functions, cluster_cb.flag_mask);
            ret = ESP_OK;
        }
    }
    return ret;
}
"""
command_callback_impl_templ = """
static esp_err_t {}(const ConcreteCommandPath &command_path, TLVReader &tlv_data, void *opaque_ptr)
{{
    chip::app::Clusters::{}::Commands::{}::DecodableType command_data;
{}
    if (error == CHIP_NO_ERROR) {{
        emberAf{}Cluster{}Callback((CommandHandler *)opaque_ptr, command_path, command_data);
    }}
    return ESP_OK;
}}
"""

static_text_file_preface = """/*
 * SPDX-FileCopyrightText: 2025 Espressif Systems (Shanghai) CO LTD
 *
 * SPDX-License-Identifier: Apache-2.0
 */

/* Generated by esp_matter_data_model_interpreter/generator_utils/cluster_cmds_gen.py (DO NOT EDIT!) */

#include <esp_err.h>
#include <esp_matter.h>
#include <esp_matter_core.h>

#include <app-common/zap-generated/callback.h>
#include <app/InteractionModelEngine.h>
#include <app/PluginApplicationCallbacks.h>

#include "cmd_c_routines.h"

using namespace chip::app::Clusters;
using chip::app::CommandHandler;
using chip::app::DataModel::Decode;
using chip::TLV::TLVReader;

#define CALL_ONCE(cb)                           \\
    [](){                                       \\
        static bool is_called = false;          \\
        if (!is_called) {                       \\
            cb();                               \\
            is_called = true;                   \\
        }                                       \\
    }

typedef struct {
    uint32_t cmd_id;
    esp_matter::command::callback_t cmd_cb;
} CommandCallbackMap_t;

typedef struct {
    uint32_t cluster_id;
    void (*init_fn)();
    const CommandCallbackMap_t (*accepted_cmds)[];
    uint32_t num_cmds;
    const EmberAfGenericClusterFunction * functions;
    uint8_t flag_mask;
} ClusterTableMap_t;
"""

cluster_table_map_instance_templ = """
    {{
        .cluster_id = {},
        .init_fn = {},
        .accepted_cmds = {},
        .num_cmds = {},
        .functions = {},
        .flag_mask = {},
    }},"""

ignore_clusters = [
    "Commodity Tariff",
    "Commodity Metering",
]

ignore_commands = {
    "Level Control": ["MoveToClosestFrequency"],
    "Smoke CO Alarm": ["SelfTestRequest"],
    "Bridged Device Basic Information": ["KeepActive"],
}

macro_dependent_clusters = {
    "ICD Management": "CONFIG_ENABLE_ICD_SERVER",
}

macro_dependent_commands = {
    "ReviewFabricRestrictions": "CHIP_CONFIG_USE_ACCESS_RESTRICTIONS",
}


class Command:
    def __init__(self, name, name_alnum, id, cb, macro_dependency="", is_fabric_scoped=False):
        self.name = name
        self.name_alnum = name_alnum
        self.id = id
        self.cb = cb
        self.macro_dependency = macro_dependency
        self.is_fabric_scoped = is_fabric_scoped


class Cluster:
    def __init__(self, name, name_alnum, id, commands, init_fn, macro_dependency=""):
        self.name = name
        self.name_alnum = name_alnum
        self.id = id
        self.commands = commands
        self.init_fn = init_fn
        self.macro_dependency = macro_dependency
        self.functions_array_name = "nullptr"
        self.flag_mask = "0"


_WORD_SPLIT = re.compile(r"[ _\-/]")      #   / |_|-|\//
_STRIP_CHARS = re.compile(r"[+\(\)&]")    #   chars removed before splitting
_NON_ID = re.compile(r"[^A-Za-z0-9_]")  #   final identifier filter


def to_camel_case(label: str, first_lower: bool) -> str:
    """
    Port of zap-templates/string.toCamelCase(label, firstLower).
    """
    cleaned = _STRIP_CHARS.sub("", label)
    tokens = _WORD_SPLIT.split(cleaned)

    def fix(tok: str, idx: int) -> str:
        if not tok:
            return tok
        is_all_upper = tok.isupper()
        head = tok[0].lower() if (idx == 0 and first_lower) else tok[0].upper()
        tail = tok[1:].lower() if is_all_upper else tok[1:]
        return head + tail

    out = "".join(fix(t, i) for i, t in enumerate(tokens))

    # Special single-word rule (identical to JS)
    if first_lower:
        if (not _WORD_SPLIT.search(label) and
            len(label) > 1 and
            label[:2].isupper() and
            not label.isupper()):
            out = out[0].upper() + out[1:]

    return _NON_ID.sub("", out)


def get_clusters_from_xml(cluster_xml_file, config_yaml_file) -> list[Cluster]:
    tree = ET.parse(cluster_xml_file)
    root = tree.getroot()

    clusters_list = []  # Initialize list

    with open(config_yaml_file, "r") as f:
        yaml_config_data = yaml.safe_load(f)

    clusters = root.findall("cluster")  # Find all clusters

    # Loop through each cluster
    for cluster in clusters:
        if cluster is not None:
            cluster_name = cluster.find("name").text
            cluster_name_alnum = to_camel_case(cluster_name, first_lower=False)
            cluster_id_tag = cluster.find("code")
            if cluster_id_tag is None or not cluster_id_tag.text:
                print(
                    f"Warning: Cluster '{cluster_name}' in {cluster_xml_file} is missing a 'code' (ID) tag or it's empty. Skipping.",
                    file=sys.stderr,
                )
                continue
            cluster_id = cluster_id_tag.text

            # Filter based on maturity/ignore lists *before* deciding on init_fn or commands
            if cluster.get("apiMaturity") in ["provisional", "internal"] or cluster_name in ignore_clusters:
                # Skip cluster entirely if ignored or provisional/internal
                continue

            plugin_init_cb = f"CALL_ONCE(Matter{cluster_name_alnum}PluginServerInitCallback)"

            # Getting cluster commands
            commands = []
            # Process commands ONLY IF the cluster is NOT listed in CommandHandlerInterfaceOnlyClusters
            if cluster_name not in yaml_config_data.get("CommandHandlerInterfaceOnlyClusters", []):
                if cluster.find("command") is not None:
                    for command in cluster.findall("command"):
                        # Check command source and maturity, plus ignore list
                        if (
                            command.get("source") == "client"
                            and command.get("apiMaturity") not in ["provisional", "internal"]
                            and (
                                cluster_name not in ignore_commands
                                or command.get("name") not in ignore_commands.get(cluster_name, [])  # Safe get
                            )
                        ):
                            command_id = command.get("code")
                            command_name = command.get("name")
                            command_name_alnum = "".join(char for char in command_name if char.isalnum())
                            command_cb = f"{cluster_name_alnum}{command_name_alnum}Callback"
                            command_is_fabric_scoped = str(command.get("isFabricScoped", "false")).lower() == "true"
                            macro_dependency = ""
                            if command_name in macro_dependent_commands:
                                macro_dependency = macro_dependent_commands[command_name]
                            commands.append(
                                Command(
                                    command_name,
                                    command_name_alnum,
                                    command_id,
                                    command_cb,
                                    macro_dependency=macro_dependency,
                                    is_fabric_scoped=command_is_fabric_scoped,
                                )
                            )

            macro_dependency = ""
            if cluster_name in macro_dependent_clusters.keys():
                macro_dependency = macro_dependent_clusters[cluster_name]

            # Create the cluster object. 'functions' and 'flag_mask' will be added later.
            clusters_list.append(
                Cluster(
                    cluster_name,
                    cluster_name_alnum,
                    cluster_id,
                    commands,
                    plugin_init_cb,
                    macro_dependency=macro_dependency,
                )
            )
        else:
            print(f"Warning: Encountered an unexpected None cluster_element in {cluster_xml_file}", file=sys.stderr)
    # Return the list of clusters
    return clusters_list


def update_cluster_flagmask_and_ember_fn_array(cluster, config_yaml_file):
    with open(config_yaml_file, "r") as f:
        yaml_config_data = yaml.safe_load(f)

    # Define the mapping between YAML list names, flag constants, and callback suffixes
    function_types = {
        "ClustersWithInitFunctions": ["esp_matter::CLUSTER_FLAG_INIT_FUNCTION", "ClusterServerInitCallback", "emberAf"],
        "ClustersWithAttributeChangedFunctions": [
            "esp_matter::CLUSTER_FLAG_ATTRIBUTE_CHANGED_FUNCTION",
            "ClusterServerAttributeChangedCallback",
            "Matter",
        ],
        "ClustersWithShutdownFunctions": [
            "esp_matter::CLUSTER_FLAG_SHUTDOWN_FUNCTION",
            "ClusterServerShutdownCallback",
            "Matter",
        ],
        "ClustersWithPreAttributeChangeFunctions": [
            "esp_matter::CLUSTER_FLAG_PRE_ATTRIBUTE_CHANGED_FUNCTION",
            "ClusterServerPreAttributeChangedCallback",
            "Matter",
        ],
    }

    active_flags = []
    function_pointers_str_list = []

    for yaml_key, (flag, suffix, prefix) in function_types.items():
        # Check if the cluster exists in the current list within the YAML data
        if cluster.name in yaml_config_data.get(yaml_key, []):
            active_flags.append(flag)
            function_pointers_str_list.append(f"(EmberAfGenericClusterFunction) {prefix}{cluster.name_alnum}{suffix},")

    cluster.flag_mask = " | ".join(active_flags) if active_flags else "0"

    if function_pointers_str_list:
        cluster.ember_func_array_content_str = "\n\t".join(function_pointers_str_list)
        cluster.functions_array_name = f"chipFuncArray{cluster.name_alnum}Server"
    else:
        cluster.ember_func_array_content_str = ""
        cluster.functions_array_name = "nullptr"


def generate_callback_functions(clusters, file):
    for cluster in clusters:
        if cluster.macro_dependency and cluster.commands:
            file.write(f"\n#if {cluster.macro_dependency}")
        for command in cluster.commands:
            if command.macro_dependency:
                file.write(f"\n#if {command.macro_dependency}")
            decode_block = "    CHIP_ERROR error = Decode(tlv_data, command_data);\n"
            if command.is_fabric_scoped:
                decode_block = (
                    "    chip::app::CommandHandler *command_obj = (chip::app::CommandHandler *)opaque_ptr;\n"
                    "    CHIP_ERROR error = command_data.Decode(tlv_data, command_obj->GetAccessingFabricIndex());\n"
                )
            file.write(
                command_callback_impl_templ.format(
                    command.cb,
                    cluster.name_alnum,
                    command.name_alnum,
                    decode_block,
                    cluster.name_alnum,
                    command.name_alnum,
                )
            )
            if command.macro_dependency:
                file.write(f"#endif /* {command.macro_dependency} */")
        if cluster.macro_dependency and cluster.commands:
            file.write(f"#endif /* {cluster.macro_dependency} */")


def generate_command_array(clusters, file):
    for cluster in clusters:
        command_callback_map = ""
        if cluster.commands:
            if cluster.macro_dependency:
                command_callback_map += f"\n#if {cluster.macro_dependency}\n"
            command_callback_map += f"const CommandCallbackMap_t {cluster.name_alnum}AcceptedCommands[] = {{\n"
            for command in cluster.commands:
                if command.macro_dependency:
                    command_callback_map += f"\n#if {command.macro_dependency}\n"
                command_callback_map += f"\t{{ {command.id}, {command.cb} }},\n"
                if command.macro_dependency:
                    command_callback_map += f"#endif /* {command.macro_dependency} */\n"
            command_callback_map += "};\n"
            if cluster.macro_dependency:
                command_callback_map += f"#endif /* {cluster.macro_dependency} */\n"
            file.write(command_callback_map)


def generate_cluster_static_arrays(clusters, file):
    generated_arrays = set()
    for cluster in clusters:
        array_name = getattr(cluster, "functions_array_name", "nullptr")
        ember_func_array_content = getattr(cluster, "ember_func_array_content_str", "")

        if array_name != "nullptr" and ember_func_array_content and array_name not in generated_arrays:
            clean_content = ember_func_array_content.strip()
            if clean_content.endswith(","):
                ember_func_array_content = ember_func_array_content[: ember_func_array_content.rfind(",")]

            ember_func_array_definition = f"const EmberAfGenericClusterFunction {array_name}[] = {{\n\t"
            ember_func_array_definition += ember_func_array_content
            ember_func_array_definition += "\n};\n"
            file.write(ember_func_array_definition)
            generated_arrays.add(array_name)

            if cluster.macro_dependency:
                file.write(f"#endif /* {cluster.macro_dependency} */\n")


def generate_cluster_struct_arrays(clusters, file):
    file.write("\nconst ClusterTableMap_t cluster_cb_map[] = {")
    # Sorting clusters by ID for consistent output
    clusters.sort(key=lambda c: int(c.id, 16))

    for cluster in clusters:
        accepted_cmds_ptr = "nullptr"
        num_cmds = 0
        if cluster.commands:
            cmd_array_name = f"{cluster.name_alnum}AcceptedCommands"
            accepted_cmds_ptr = f"&{cmd_array_name}"
            num_cmds = len(cluster.commands) + 1

        functions_ptr = cluster.functions_array_name

        mask = cluster.flag_mask
        if not mask or mask == "0":
            mask = "0"

        if cluster.macro_dependency:
            file.write(f"\n#if {cluster.macro_dependency}")

        try:
            formatted_entry = cluster_table_map_instance_templ.format(
                cluster.id, cluster.init_fn, accepted_cmds_ptr, num_cmds, functions_ptr, mask
            )
            file.write(formatted_entry)
        except Exception as fmt_err:
            print(f"ERROR formatting entry for cluster {cluster.id}: {fmt_err}", file=sys.stderr)
            file.write(f"\n    #error GENERATING ENTRY for cluster {cluster.id}\n")

        if cluster.macro_dependency:
            file.write(f"\n#endif /* {cluster.macro_dependency} */")
    file.write("\n};\n")


if __name__ == "__main__":
    default_xml_dir = os.path.expandvars(
        os.path.join(
            os.environ.get("ESP_MATTER_PATH"),
            "connectedhomeip",
            "connectedhomeip",
            "src",
            "app",
            "zap-templates",
            "zcl",
            "data-model",
            "chip",
        )
    )
    default_config_yaml = os.path.expandvars(
        os.path.join(
            os.environ.get("ESP_MATTER_PATH"),
            "connectedhomeip",
            "connectedhomeip",
            "src",
            "app",
            "common",
            "templates",
            "config-data.yaml",
        )
    )

    parser = argparse.ArgumentParser(description="Generate Matter command routines file.")
    parser.add_argument("-o", "--output_file", required=True, help="File path where the output file will be written")
    parser.add_argument("-x", "--xml_dir", default=default_xml_dir, help="Directory containing Matter cluster XML definitions")
    parser.add_argument("-c", "--config_yaml", default=default_config_yaml, help="Path to the config-data.yaml file")
    args = parser.parse_args()

    if not os.path.isdir(args.xml_dir):
        print(f"Error: XML directory not found: {args.xml_dir}", file=sys.stderr)
        exit(1)
    if not os.path.isfile(args.config_yaml):
        print(f"Error: Config YAML not found: {args.config_yaml}", file=sys.stderr)
        exit(1)

    print(f"Using XML directory: {args.xml_dir}", file=sys.stderr)
    print(f"Using config YAML: {args.config_yaml}", file=sys.stderr)
    print(f"Output file: {args.output_file}", file=sys.stderr)

    clusters = []
    processed_cluster_ids = set()

    for filename in sorted(os.listdir(args.xml_dir)):
        if filename.endswith(".xml"):
            file_path = os.path.join(args.xml_dir, filename)
            try:
                clusters_in_file = get_clusters_from_xml(file_path, args.config_yaml)
                for cluster_obj in clusters_in_file:
                    if cluster_obj:
                        if cluster_obj.id not in processed_cluster_ids:
                            update_cluster_flagmask_and_ember_fn_array(cluster_obj, args.config_yaml)
                            clusters.append(cluster_obj)
                            processed_cluster_ids.add(cluster_obj.id)
                        else:
                            print(
                                f"Warning: Duplicate cluster ID {cluster_obj.id} encountered (from {filename}). Using first instance.",
                                file=sys.stderr,
                            )
            except ET.ParseError as e:
                print(f"Error parsing XML file {filename}: {e}", file=sys.stderr)
            except Exception as e:
                print(f"Error processing {filename}: {e}", file=sys.stderr)

    try:
        with open(args.output_file, "w") as file:
            file.write(static_text_file_preface)
            generate_callback_functions(clusters, file)
            generate_command_array(clusters, file)
            generate_cluster_static_arrays(clusters, file)  # Define the arrays first
            generate_cluster_struct_arrays(clusters, file)  # THEN generate the map that uses them
            file.write(static_text_register_command_cb_fn)
            file.write(static_text_cluster_plugin_init_fn)
        print(f"Successfully generated {args.output_file}", file=sys.stderr)
    except IOError as e:
        print(f"Error writing to output file {args.output_file}: {e}", file=sys.stderr)
        exit(1)
    except Exception as e:
        print(f"An unexpected error occurred during file generation: {e}", file=sys.stderr)
        exit(1)
